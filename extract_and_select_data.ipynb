{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yahoo_fin.stock_info as si\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     MMM\n",
      "1     AOS\n",
      "2     ABT\n",
      "3    ABBV\n",
      "4     ACN\n",
      "5    ADBE\n",
      "6     AMD\n",
      "7     AES\n",
      "8     AFL\n",
      "9       A\n",
      "Name: Symbol, dtype: object\n",
      "Total de empresas:  503\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "SP500_company_data = pd.read_html(url)[0]\n",
    "SP500_company_data.to_csv(\"companies_data.csv\")\n",
    "\n",
    "print(SP500_company_data['Symbol'][:10])\n",
    "print('Total de empresas: ',len(SP500_company_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model, we are going to use data from 01/01/2010 until 31/10/2023 for the training and from 01/11/2023 until 31/12/2023 for the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_train_data = pd.DataFrame()\n",
    "\n",
    "for company in SP500_company_data['Symbol']:\n",
    "    try:\n",
    "        company_data = si.get_data(company, start_date=\"01/01/2013\", end_date=\"11/01/2023\", index_as_date = True, interval=\"1d\")\n",
    "        SP500_train_data = pd.concat([SP500_train_data, company_data])\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "SP500_train_data.to_csv(\"stocks_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>78.754181</td>\n",
       "      <td>79.255852</td>\n",
       "      <td>78.561874</td>\n",
       "      <td>79.247490</td>\n",
       "      <td>54.016663</td>\n",
       "      <td>3835213</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>78.879601</td>\n",
       "      <td>79.372910</td>\n",
       "      <td>78.704010</td>\n",
       "      <td>79.155518</td>\n",
       "      <td>53.953945</td>\n",
       "      <td>3234702</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>79.255852</td>\n",
       "      <td>79.832779</td>\n",
       "      <td>79.046822</td>\n",
       "      <td>79.740807</td>\n",
       "      <td>54.352905</td>\n",
       "      <td>3235060</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>79.448158</td>\n",
       "      <td>80.041809</td>\n",
       "      <td>79.230766</td>\n",
       "      <td>79.841141</td>\n",
       "      <td>54.421295</td>\n",
       "      <td>3283977</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>79.573578</td>\n",
       "      <td>80.058525</td>\n",
       "      <td>79.515053</td>\n",
       "      <td>79.849495</td>\n",
       "      <td>54.426987</td>\n",
       "      <td>3175978</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>165.559998</td>\n",
       "      <td>165.990005</td>\n",
       "      <td>162.350006</td>\n",
       "      <td>163.669998</td>\n",
       "      <td>161.677780</td>\n",
       "      <td>1273600</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>162.270004</td>\n",
       "      <td>162.289993</td>\n",
       "      <td>157.880005</td>\n",
       "      <td>158.070007</td>\n",
       "      <td>156.145966</td>\n",
       "      <td>2891100</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>157.929993</td>\n",
       "      <td>157.929993</td>\n",
       "      <td>155.160004</td>\n",
       "      <td>156.029999</td>\n",
       "      <td>154.130798</td>\n",
       "      <td>2407100</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>157.130005</td>\n",
       "      <td>158.410004</td>\n",
       "      <td>153.520004</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>155.088959</td>\n",
       "      <td>2756200</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>157.509995</td>\n",
       "      <td>158.529999</td>\n",
       "      <td>156.089996</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>155.460297</td>\n",
       "      <td>3208900</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "2013-01-02   78.754181   79.255852   78.561874   79.247490   54.016663   \n",
       "2013-01-03   78.879601   79.372910   78.704010   79.155518   53.953945   \n",
       "2013-01-04   79.255852   79.832779   79.046822   79.740807   54.352905   \n",
       "2013-01-07   79.448158   80.041809   79.230766   79.841141   54.421295   \n",
       "2013-01-08   79.573578   80.058525   79.515053   79.849495   54.426987   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-10-25  165.559998  165.990005  162.350006  163.669998  161.677780   \n",
       "2023-10-26  162.270004  162.289993  157.880005  158.070007  156.145966   \n",
       "2023-10-27  157.929993  157.929993  155.160004  156.029999  154.130798   \n",
       "2023-10-30  157.130005  158.410004  153.520004  157.000000  155.088959   \n",
       "2023-10-31  157.509995  158.529999  156.089996  157.000000  155.460297   \n",
       "\n",
       "             volume ticker  \n",
       "2013-01-02  3835213    MMM  \n",
       "2013-01-03  3234702    MMM  \n",
       "2013-01-04  3235060    MMM  \n",
       "2013-01-07  3283977    MMM  \n",
       "2013-01-08  3175978    MMM  \n",
       "...             ...    ...  \n",
       "2023-10-25  1273600    ZTS  \n",
       "2023-10-26  2891100    ZTS  \n",
       "2023-10-27  2407100    ZTS  \n",
       "2023-10-30  2756200    ZTS  \n",
       "2023-10-31  3208900    ZTS  \n",
       "\n",
       "[1310475 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_test_data = pd.DataFrame()\n",
    "\n",
    "for company in SP500_company_data['Symbol']:\n",
    "    try:\n",
    "        company_data = si.get_data(company, start_date=\"10/25/2023\", end_date=\"12/31/2023\", index_as_date = True, interval=\"1d\")\n",
    "        SP500_test_data = pd.concat([SP500_test_data, company_data])\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "SP500_test_data.to_csv(\"stocks_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>195.320007</td>\n",
       "      <td>195.910004</td>\n",
       "      <td>192.740005</td>\n",
       "      <td>194.979996</td>\n",
       "      <td>193.067825</td>\n",
       "      <td>1548400</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>194.880005</td>\n",
       "      <td>196.339996</td>\n",
       "      <td>194.089996</td>\n",
       "      <td>195.500000</td>\n",
       "      <td>193.582733</td>\n",
       "      <td>814600</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>195.410004</td>\n",
       "      <td>197.009995</td>\n",
       "      <td>194.740005</td>\n",
       "      <td>196.899994</td>\n",
       "      <td>194.968994</td>\n",
       "      <td>766400</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>197.619995</td>\n",
       "      <td>198.600006</td>\n",
       "      <td>196.529999</td>\n",
       "      <td>197.160004</td>\n",
       "      <td>195.226456</td>\n",
       "      <td>880100</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>196.679993</td>\n",
       "      <td>198.009995</td>\n",
       "      <td>196.250000</td>\n",
       "      <td>197.369995</td>\n",
       "      <td>195.434387</td>\n",
       "      <td>1007200</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "2023-12-22  195.320007  195.910004  192.740005  194.979996  193.067825   \n",
       "2023-12-26  194.880005  196.339996  194.089996  195.500000  193.582733   \n",
       "2023-12-27  195.410004  197.009995  194.740005  196.899994  194.968994   \n",
       "2023-12-28  197.619995  198.600006  196.529999  197.160004  195.226456   \n",
       "2023-12-29  196.679993  198.009995  196.250000  197.369995  195.434387   \n",
       "\n",
       "             volume ticker  \n",
       "2023-12-22  1548400    ZTS  \n",
       "2023-12-26   814600    ZTS  \n",
       "2023-12-27   766400    ZTS  \n",
       "2023-12-28   880100    ZTS  \n",
       "2023-12-29  1007200    ZTS  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar se as empresas são iguais em ambos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets contem as mesmas empresas, sendo o numero total: 497\n"
     ]
    }
   ],
   "source": [
    "# verificar se contem o msm numero de empresas\n",
    "train_ind = SP500_train_data[\"ticker\"].unique()\n",
    "test_ind = SP500_test_data[\"ticker\"].unique()\n",
    "\n",
    "diff = False\n",
    "for ticker in train_ind:\n",
    "    if ticker not in test_ind:\n",
    "        diff = True\n",
    "        break\n",
    "\n",
    "if diff: print(\"Datasets contem diferentes empresas\")\n",
    "else: print(\"Datasets contem as mesmas empresas, sendo o numero total: %d\" % len(test_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos decidir quais empresas usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos escolher os 5 melhores setores e as respetivas 30 melhores empresas com base no <b> crescimento mensal </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar os dados\n",
    "SP500_company_data = pd.read_csv(\"companies_data.csv\", index_col=0)\n",
    "SP500_test_data = pd.read_csv(\"stocks_test_data.csv\", index_col=0)\n",
    "SP500_test_data.index = pd.to_datetime(SP500_test_data.index)\n",
    "SP500_train_data = pd.read_csv(\"stocks_train_data.csv\", index_col=0)\n",
    "SP500_train_data.index = pd.to_datetime(SP500_train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de empresas no setor 'Industrials' -> 78\n",
      "Total de empresas no setor 'Health Care' -> 62\n",
      "Total de empresas no setor 'Information Technology' -> 69\n",
      "Total de empresas no setor 'Utilities' -> 31\n",
      "Total de empresas no setor 'Financials' -> 72\n",
      "Total de empresas no setor 'Materials' -> 28\n",
      "Total de empresas no setor 'Consumer Discretionary' -> 50\n",
      "Total de empresas no setor 'Real Estate' -> 31\n",
      "Total de empresas no setor 'Communication Services' -> 22\n",
      "Total de empresas no setor 'Consumer Staples' -> 38\n",
      "Total de empresas no setor 'Energy' -> 22\n"
     ]
    }
   ],
   "source": [
    "for sector in SP500_company_data[\"GICS Sector\"].unique():\n",
    "    n_empresas = SP500_company_data[SP500_company_data[\"GICS Sector\"] == sector][\"GICS Sector\"].count()\n",
    "    print(f\"Total de empresas no setor '{sector}' -> {n_empresas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth(df):\n",
    "    # retorna o crescimento mensal da empresa \n",
    "    monthly_growth = 0\n",
    "    monthly = df['close'].resample('ME').agg(['first', 'last'])\n",
    "    \n",
    "    for _, row in monthly.iterrows():\n",
    "        monthly_growth += ((row['last'] - row['first']) / row['first']) * 100\n",
    "        \n",
    "    return monthly_growth/len(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>78.754181</td>\n",
       "      <td>79.255852</td>\n",
       "      <td>78.561874</td>\n",
       "      <td>79.247490</td>\n",
       "      <td>54.016663</td>\n",
       "      <td>3835213</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>78.879601</td>\n",
       "      <td>79.372910</td>\n",
       "      <td>78.704010</td>\n",
       "      <td>79.155518</td>\n",
       "      <td>53.953945</td>\n",
       "      <td>3234702</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>79.255852</td>\n",
       "      <td>79.832779</td>\n",
       "      <td>79.046822</td>\n",
       "      <td>79.740807</td>\n",
       "      <td>54.352905</td>\n",
       "      <td>3235060</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>79.448158</td>\n",
       "      <td>80.041809</td>\n",
       "      <td>79.230766</td>\n",
       "      <td>79.841141</td>\n",
       "      <td>54.421295</td>\n",
       "      <td>3283977</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>79.573578</td>\n",
       "      <td>80.058525</td>\n",
       "      <td>79.515053</td>\n",
       "      <td>79.849495</td>\n",
       "      <td>54.426987</td>\n",
       "      <td>3175978</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>165.559998</td>\n",
       "      <td>165.990005</td>\n",
       "      <td>162.350006</td>\n",
       "      <td>163.669998</td>\n",
       "      <td>161.677780</td>\n",
       "      <td>1273600</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>162.270004</td>\n",
       "      <td>162.289993</td>\n",
       "      <td>157.880005</td>\n",
       "      <td>158.070007</td>\n",
       "      <td>156.145966</td>\n",
       "      <td>2891100</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>157.929993</td>\n",
       "      <td>157.929993</td>\n",
       "      <td>155.160004</td>\n",
       "      <td>156.029999</td>\n",
       "      <td>154.130798</td>\n",
       "      <td>2407100</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>157.130005</td>\n",
       "      <td>158.410004</td>\n",
       "      <td>153.520004</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>155.088959</td>\n",
       "      <td>2756200</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>157.509995</td>\n",
       "      <td>158.529999</td>\n",
       "      <td>156.089996</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>155.460297</td>\n",
       "      <td>3208900</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "2013-01-02   78.754181   79.255852   78.561874   79.247490   54.016663   \n",
       "2013-01-03   78.879601   79.372910   78.704010   79.155518   53.953945   \n",
       "2013-01-04   79.255852   79.832779   79.046822   79.740807   54.352905   \n",
       "2013-01-07   79.448158   80.041809   79.230766   79.841141   54.421295   \n",
       "2013-01-08   79.573578   80.058525   79.515053   79.849495   54.426987   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-10-25  165.559998  165.990005  162.350006  163.669998  161.677780   \n",
       "2023-10-26  162.270004  162.289993  157.880005  158.070007  156.145966   \n",
       "2023-10-27  157.929993  157.929993  155.160004  156.029999  154.130798   \n",
       "2023-10-30  157.130005  158.410004  153.520004  157.000000  155.088959   \n",
       "2023-10-31  157.509995  158.529999  156.089996  157.000000  155.460297   \n",
       "\n",
       "             volume ticker  \n",
       "2013-01-02  3835213    MMM  \n",
       "2013-01-03  3234702    MMM  \n",
       "2013-01-04  3235060    MMM  \n",
       "2013-01-07  3283977    MMM  \n",
       "2013-01-08  3175978    MMM  \n",
       "...             ...    ...  \n",
       "2023-10-25  1273600    ZTS  \n",
       "2023-10-26  2891100    ZTS  \n",
       "2023-10-27  2407100    ZTS  \n",
       "2023-10-30  2756200    ZTS  \n",
       "2023-10-31  3208900    ZTS  \n",
       "\n",
       "[1310475 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = {}\n",
    "sectors_growth = {}\n",
    "for sector in SP500_company_data[\"GICS Sector\"].unique():\n",
    "    mean_growth_sector = 0\n",
    "    sector_data = SP500_company_data[SP500_company_data[\"GICS Sector\"] == sector]\n",
    "    data = {}\n",
    "    \n",
    "    for company in sector_data[\"Symbol\"]: \n",
    "        try:\n",
    "            stock_growth = get_growth(SP500_train_data[SP500_train_data[\"ticker\"]==company])\n",
    "            mean_growth_sector += stock_growth\n",
    "            data[company] = stock_growth\n",
    "        except:\n",
    "            ...\n",
    "    growth[sector] = dict(sorted(data.items(), key=lambda item: item[1], reverse=True)) # ordenar por ordem decrescente\n",
    "    sectors_growth[sector] = mean_growth_sector/len(data)\n",
    "# ordenar em forma decrescente\n",
    "sectors_growth = dict(sorted(sectors_growth.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar os melhores setores e respetivas melhores empresas\n",
    "\n",
    "Identificamos quais os 5 melhores setores e as respetivas 30 melhores empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Setor: Information Technology (avg monthly growth: 1.6906%) - all companies in sector\n",
      "    < 30 best companies >\n",
      "    PLTR - avg monthly growth: 4.8093%\n",
      "    ENPH - avg monthly growth: 4.5056%\n",
      "    NVDA - avg monthly growth: 4.3222%\n",
      "    AMD - avg monthly growth: 3.2526%\n",
      "    CRWD - avg monthly growth: 3.1527%\n",
      "    ANET - avg monthly growth: 2.9773%\n",
      "    AVGO - avg monthly growth: 2.8534%\n",
      "    NOW - avg monthly growth: 2.7821%\n",
      "    MPWR - avg monthly growth: 2.6723%\n",
      "    PANW - avg monthly growth: 2.6632%\n",
      "    SMCI - avg monthly growth: 2.6045%\n",
      "    EPAM - avg monthly growth: 2.5880%\n",
      "    FTNT - avg monthly growth: 2.4486%\n",
      "    CDNS - avg monthly growth: 2.4176%\n",
      "    LRCX - avg monthly growth: 2.3566%\n",
      "    FICO - avg monthly growth: 2.3395%\n",
      "    SNPS - avg monthly growth: 2.2480%\n",
      "    ADBE - avg monthly growth: 2.1802%\n",
      "    MU - avg monthly growth: 2.1777%\n",
      "    AMAT - avg monthly growth: 2.0917%\n",
      "    ZBRA - avg monthly growth: 2.0421%\n",
      "    MSFT - avg monthly growth: 2.0040%\n",
      "    KLAC - avg monthly growth: 1.9861%\n",
      "    ON - avg monthly growth: 1.9701%\n",
      "    DELL - avg monthly growth: 1.9377%\n",
      "    FSLR - avg monthly growth: 1.9212%\n",
      "    KEYS - avg monthly growth: 1.8215%\n",
      "    CDW - avg monthly growth: 1.7981%\n",
      "    INTU - avg monthly growth: 1.7805%\n",
      "    IT - avg monthly growth: 1.6867%\n",
      "2) Setor: Health Care (avg monthly growth: 1.2401%) - all companies in sector\n",
      "    < 30 best companies >\n",
      "    MRNA - avg monthly growth: 5.5911%\n",
      "    DXCM - avg monthly growth: 3.4253%\n",
      "    WST - avg monthly growth: 2.2517%\n",
      "    PODD - avg monthly growth: 2.1919%\n",
      "    ALGN - avg monthly growth: 2.0981%\n",
      "    IDXX - avg monthly growth: 2.0896%\n",
      "    GEHC - avg monthly growth: 2.0258%\n",
      "    MOH - avg monthly growth: 2.0192%\n",
      "    LLY - avg monthly growth: 1.9656%\n",
      "    BSX - avg monthly growth: 1.8059%\n",
      "    VRTX - avg monthly growth: 1.7901%\n",
      "    UNH - avg monthly growth: 1.7622%\n",
      "    ELV - avg monthly growth: 1.7397%\n",
      "    HCA - avg monthly growth: 1.6434%\n",
      "    CNC - avg monthly growth: 1.6272%\n",
      "    HUM - avg monthly growth: 1.5449%\n",
      "    STE - avg monthly growth: 1.5065%\n",
      "    TMO - avg monthly growth: 1.4782%\n",
      "    DHR - avg monthly growth: 1.4752%\n",
      "    EW - avg monthly growth: 1.4423%\n",
      "    CRL - avg monthly growth: 1.4032%\n",
      "    CI - avg monthly growth: 1.3799%\n",
      "    SYK - avg monthly growth: 1.3660%\n",
      "    IQV - avg monthly growth: 1.3555%\n",
      "    CTLT - avg monthly growth: 1.3245%\n",
      "    ISRG - avg monthly growth: 1.3228%\n",
      "    MTD - avg monthly growth: 1.2378%\n",
      "    MCK - avg monthly growth: 1.2208%\n",
      "    RMD - avg monthly growth: 1.1965%\n",
      "    ABBV - avg monthly growth: 1.1674%\n",
      "3) Setor: Consumer Discretionary (avg monthly growth: 1.2011%) - all companies in sector\n",
      "    < 30 best companies >\n",
      "    TSLA - avg monthly growth: 4.7046%\n",
      "    CZR - avg monthly growth: 3.9394%\n",
      "    RCL - avg monthly growth: 2.0774%\n",
      "    AMZN - avg monthly growth: 2.0726%\n",
      "    DECK - avg monthly growth: 2.0285%\n",
      "    CMG - avg monthly growth: 1.9757%\n",
      "    DPZ - avg monthly growth: 1.8690%\n",
      "    ORLY - avg monthly growth: 1.8600%\n",
      "    BBY - avg monthly growth: 1.8354%\n",
      "    AZO - avg monthly growth: 1.6795%\n",
      "    POOL - avg monthly growth: 1.6521%\n",
      "    MAR - avg monthly growth: 1.6242%\n",
      "    DRI - avg monthly growth: 1.5750%\n",
      "    ULTA - avg monthly growth: 1.5424%\n",
      "    DHI - avg monthly growth: 1.5279%\n",
      "    LULU - avg monthly growth: 1.5141%\n",
      "    ROST - avg monthly growth: 1.4385%\n",
      "    LOW - avg monthly growth: 1.4243%\n",
      "    TSCO - avg monthly growth: 1.3610%\n",
      "    MGM - avg monthly growth: 1.3560%\n",
      "    PHM - avg monthly growth: 1.3525%\n",
      "    HLT - avg monthly growth: 1.3523%\n",
      "    NVR - avg monthly growth: 1.3500%\n",
      "    HD - avg monthly growth: 1.2755%\n",
      "    TJX - avg monthly growth: 1.2436%\n",
      "    BKNG - avg monthly growth: 1.2431%\n",
      "    NKE - avg monthly growth: 1.2074%\n",
      "    SBUX - avg monthly growth: 1.0825%\n",
      "    MCD - avg monthly growth: 1.0442%\n",
      "    LEN - avg monthly growth: 1.0241%\n",
      "4) Setor: Industrials (avg monthly growth: 1.0757%) - all companies in sector\n",
      "    < 30 best companies >\n",
      "    CARR - avg monthly growth: 3.7028%\n",
      "    PAYC - avg monthly growth: 3.1632%\n",
      "    AXON - avg monthly growth: 2.9902%\n",
      "    BLDR - avg monthly growth: 2.4877%\n",
      "    ODFL - avg monthly growth: 2.2789%\n",
      "    URI - avg monthly growth: 2.2693%\n",
      "    CTAS - avg monthly growth: 2.1584%\n",
      "    CPRT - avg monthly growth: 1.9983%\n",
      "    IR - avg monthly growth: 1.9286%\n",
      "    PWR - avg monthly growth: 1.7055%\n",
      "    ROL - avg monthly growth: 1.6727%\n",
      "    NOC - avg monthly growth: 1.6491%\n",
      "    TT - avg monthly growth: 1.5796%\n",
      "    BR - avg monthly growth: 1.5753%\n",
      "    HII - avg monthly growth: 1.5316%\n",
      "    DAY - avg monthly growth: 1.5004%\n",
      "    TDG - avg monthly growth: 1.4889%\n",
      "    GNRC - avg monthly growth: 1.4852%\n",
      "    WM - avg monthly growth: 1.4575%\n",
      "    RSG - avg monthly growth: 1.4172%\n",
      "    ADP - avg monthly growth: 1.4091%\n",
      "    CSX - avg monthly growth: 1.3745%\n",
      "    HWM - avg monthly growth: 1.3453%\n",
      "    LMT - avg monthly growth: 1.3296%\n",
      "    OTIS - avg monthly growth: 1.3091%\n",
      "    DAL - avg monthly growth: 1.2802%\n",
      "    GWW - avg monthly growth: 1.2746%\n",
      "    PH - avg monthly growth: 1.2308%\n",
      "    IEX - avg monthly growth: 1.2247%\n",
      "    XYL - avg monthly growth: 1.2118%\n",
      "5) Setor: Energy (avg monthly growth: 1.0063%) - all companies in sector\n",
      "    < 30 best companies >\n",
      "    TPL - avg monthly growth: 3.2960%\n",
      "    FANG - avg monthly growth: 2.2994%\n",
      "    TRGP - avg monthly growth: 1.9132%\n",
      "    APA - avg monthly growth: 1.6494%\n",
      "    VLO - avg monthly growth: 1.6149%\n",
      "    MPC - avg monthly growth: 1.5951%\n",
      "    OKE - avg monthly growth: 1.3642%\n",
      "    HES - avg monthly growth: 1.2820%\n",
      "    EQT - avg monthly growth: 1.1588%\n",
      "    EOG - avg monthly growth: 0.9961%\n",
      "    DVN - avg monthly growth: 0.8414%\n",
      "    PSX - avg monthly growth: 0.7635%\n",
      "    HAL - avg monthly growth: 0.7409%\n",
      "    COP - avg monthly growth: 0.6997%\n",
      "    CTRA - avg monthly growth: 0.4390%\n",
      "    OXY - avg monthly growth: 0.4356%\n",
      "    WMB - avg monthly growth: 0.3264%\n",
      "    SLB - avg monthly growth: 0.2852%\n",
      "    CVX - avg monthly growth: 0.2803%\n",
      "    BKR - avg monthly growth: 0.2531%\n",
      "    XOM - avg monthly growth: 0.1515%\n",
      "    KMI - avg monthly growth: -0.2473%\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"dataset_by_sector/\"):\n",
    "    os.mkdir(\"dataset_by_sector/\")\n",
    "    \n",
    "metadata = pd.DataFrame(columns=['ticker', 'sector', 'model'])\n",
    "# metadata = metadata.append({'tinker': 'Tinker3', 'sector': 'Sector3', 'model': 'Model3'}, ignore_index=True)\n",
    "j = 1\n",
    "for sector,m_growth in sectors_growth.items():\n",
    "    if j > 5: break\n",
    "    i = 1\n",
    "    print(f\"{j}) Setor: {sector} (avg monthly growth: {m_growth:.4f}%) - all companies in sector\")\n",
    "    print(\"    < 30 best companies >\")\n",
    "    for company,data in growth[sector].items():\n",
    "        if i > 30: break\n",
    "        print(f\"    {company} - avg monthly growth: {data:.4f}%\")\n",
    "        metadata.loc[len(metadata)] = [company,sector.replace(\" \",\"_\"),\"por_definir\"]\n",
    "        # quando criarmos os modelos vamos associar a cada stock\n",
    "        i += 1\n",
    "    j += 1\n",
    "metadata.to_csv(f\"dataset_by_sector/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar os dados\n",
    "\n",
    "Vamos agora guardar os dados das 30 melhores empresas por setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"dataset_by_sector/train/\"):\n",
    "    os.mkdir(\"dataset_by_sector/train/\")\n",
    "    \n",
    "if not os.path.exists(\"dataset_by_sector/test/\"):\n",
    "    os.mkdir(\"dataset_by_sector/test/\")    \n",
    "    \n",
    "limit_sector = 1\n",
    "\n",
    "for sector,m_growth in sectors_growth.items():\n",
    "    if limit_sector > 5: break\n",
    "    limit_companies = 1\n",
    "    \n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "    \n",
    "    for company,data in growth[sector].items():\n",
    "        if limit_companies > 30: break\n",
    "\n",
    "        df_train = pd.concat([df_train,SP500_train_data[SP500_train_data[\"ticker\"]==company]])\n",
    "        df_test = pd.concat([df_test,SP500_test_data[SP500_test_data[\"ticker\"]==company]])\n",
    "        limit_companies += 1\n",
    "\n",
    "    df_train.to_csv(f\"dataset_by_sector/train/{sector.replace(' ','_')}.csv\")\n",
    "    df_test.to_csv(f\"dataset_by_sector/test/{sector.replace(' ','_')}.csv\")\n",
    "    limit_sector += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remover os datasets iniciais \n",
    "\n",
    "Remover os datasets que já não são necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ficheiro 'companies_data.csv' removido com sucesso.\n",
      "Ficheiro 'stocks_train_data.csv' removido com sucesso.\n",
      "Ficheiro 'stocks_test_data.csv' removido com sucesso.\n"
     ]
    }
   ],
   "source": [
    "del_files = [\"companies_data.csv\",\"stocks_train_data.csv\",\"stocks_test_data.csv\"]\n",
    "\n",
    "for csv_file in del_files:\n",
    "    if os.path.exists(csv_file):\n",
    "        os.remove(csv_file)\n",
    "        print(f\"Ficheiro '{csv_file}' removido com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Ficheiro '{csv_file}' não encontrado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte do chico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decidir empresas com melhor crescimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stocks_train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstocks_train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      6\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentile Growth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ((data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stocks_train_data.csv'"
     ]
    }
   ],
   "source": [
    "file_path = \"stocks_train_data.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "if 'open' in data.columns and 'close' in data.columns and 'ticker' in data.columns:\n",
    "\n",
    "    data['Percentile Growth'] = ((data['close'] - data['open']) / data['open']) * 100\n",
    "\n",
    "    unique_companies = data.loc[data.groupby('ticker')['Percentile Growth'].idxmax()]\n",
    "\n",
    "    sorted_data = unique_companies.sort_values(by='Percentile Growth', ascending=False)\n",
    "\n",
    "    top_20_companies = sorted_data.head(50)\n",
    "\n",
    "    print(top_20_companies[['ticker', 'open', 'close', 'Percentile Growth']])\n",
    "\n",
    "    top_20_companies.to_csv(\"top_20_companies_1day.csv\", index=False)\n",
    "else:\n",
    "    print(\"Data is missing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  Média Crescimento Diário\n",
      "465   VLTO                  0.586928\n",
      "83     CEG                  0.238511\n",
      "73    CARR                  0.165847\n",
      "438    TPL                  0.157252\n",
      "3     ABNB                  0.119603\n",
      "..     ...                       ...\n",
      "220    HII                  0.058211\n",
      "156    ELV                  0.057973\n",
      "396    ROL                  0.057695\n",
      "447     TT                  0.057579\n",
      "119   CTVA                  0.057425\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"stocks_train_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "if 'open' in data.columns and 'close' in data.columns and 'ticker' in data.columns:\n",
    "\n",
    "    data['Percentual Crescimento Diário'] = ((data['close'] - data['open']) / data['open']) * 100\n",
    "\n",
    "    media_crescimento = data.groupby('ticker')['Percentual Crescimento Diário'].mean().reset_index()\n",
    "\n",
    "    media_crescimento.rename(columns={'Percentual Crescimento Diário': 'Média Crescimento Diário'}, inplace=True)\n",
    "\n",
    "    top_50_empresas = media_crescimento.sort_values(by='Média Crescimento Diário', ascending=False).head(100)\n",
    "\n",
    "    print(top_50_empresas)\n",
    "\n",
    "    top_50_empresas.to_csv(\"top_50_empresas_daily average.csv\", index=False)\n",
    "else:\n",
    "    print(\"Data is missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  First_Open   Last_Close  Percentual Crescimento\n",
      "445   TSLA    1.266667   248.479996            19516.836476\n",
      "341   NVDA    0.462750    49.521999            10601.674913\n",
      "331   NFLX    7.931429   486.880005             6038.616515\n",
      "43    AVGO    1.830000   111.625000             5999.726633\n",
      "147   DXCM    2.052500   124.089996             5945.797601\n",
      "46    AXON    4.460000   258.329987             5692.152116\n",
      "460    URI    9.920000   573.419983             5680.443332\n",
      "185   FICO   21.379999  1164.010010             5344.387537\n",
      "438    TPL   10.146667   524.150024             5065.736186\n",
      "141    DPZ    8.530000   412.230011             4732.708369\n",
      "80    CDNS    6.010000   272.369995             4431.946502\n",
      "347   ODFL    4.548148   202.664993             4355.989259\n",
      "61    BLDR    3.930000   166.940002             4147.837140\n",
      "390   REGN   24.240000   878.289978             3523.308524\n",
      "285   LULU   15.435000   511.290009             3212.536408\n",
      "193   FTNT    1.788000    58.529999             3173.489887\n",
      "335    NOW   23.750000   706.489990             2874.694696\n",
      "315   MPWR   24.350000   630.780029             2490.472359\n",
      "95     CMG    1.792000    45.739201             2452.410669\n",
      "456   ULTA   19.230000   489.989990             2448.049932\n"
     ]
    }
   ],
   "source": [
    "file_path = \"stocks_train_data.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "if 'open' in data.columns and 'close' in data.columns and 'ticker' in data.columns:\n",
    "    grouped = data.groupby('ticker')\n",
    "\n",
    "    summary = grouped.agg(\n",
    "        First_Open=('open', 'first'),\n",
    "        Last_Close=('close', 'last')\n",
    "    ).reset_index()\n",
    "\n",
    "    summary['Percentual Crescimento'] = ((summary['Last_Close'] - summary['First_Open']) / summary['First_Open']) * 100\n",
    "\n",
    "    top_100_empresas = summary.sort_values(by='Percentual Crescimento', ascending=False).head(20)\n",
    "\n",
    "    print(top_100_empresas)\n",
    "\n",
    "    top_100_empresas.to_csv(\"top_100_empresas.csv\", index=False)\n",
    "else:\n",
    "    print(\"Erro: As colunas necessárias ('open', 'close', 'ticker') estão ausentes nos dados.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
